# OPEA Release Notes v0.6

## OPEA Highlight

* Add 4 MegaService examples: CodeGen, ChatQnA, CodeTrans and Docsum, you can deploy them on Kubernetes
* Enable 10 microservices for LLM, RAG, security...etc
* Support text generation, code generation and end-to-end evaluation

## GenAIExamples

* Build 4 reference solutions for some classic GenAI applications, like code generation, chat Q&A, code translation and document summarization, through orchestration interface in GenAIComps.
* Support seamlessly deployment on Intel Xeon and Gaudi platform through Kubernetes and Docker Compose.

## GenAIComps

* Activate a suite of microservices including ASR, LLMS, Rerank, Embedding, Guardrails, TTS, Telemetry, DataPrep, Retrieval, and VectorDB. ASR functionality is fully operational on Xeon architecture, pending readiness on Gaudi. Retrieval capabilities are functional on LangChain, awaiting readiness on LlamaIndex. VectorDB functionality is supported on Redis, Chroma, and Qdrant, with readiness pending on SVS.
* Added 14 file formats support in data preparation microservices and enabled Safeguard of conversation in guardrails.
* Added the Ray Gaudi Supported for LLM Service.

## GenAIEvals

* Add evaluating the models on text-generation tasks(lm-evaluation-harness) and coding tasks (bigcode-evaluation-harness)
* Add end-to-end evaluation with microservice

## GenAIInfra

* Add Helm Charts redis-vector-db, TEI, TGI and CodeGen for deploying GenAIExamples on Kubernetes
* Add Manifests for deploying GenAIExamples CodeGen, ChatQnA and Docsum on Kubernetes and on Docker Compose
